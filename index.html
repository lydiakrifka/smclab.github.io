<!doctype html>
<html lang="en" class="scroll-smooth">

<head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="./src/favicon.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lydia</title>
    <!-- <link rel="stylesheet" href="/src/style.css" /> -->
    <script type="module" src="/src/main.ts"></script>
</head>

<body>
    <main class="font-serif text-2xl/8 md:text-4xl/13">
        <div class="relative w-full h-screen flex items-center">
            <img class="absolute w-full h-full object-cover" src="./src/images/_DSC6046.JPG" srcset="
            ./src/images/_DSC6046.JPG 1024w,
            ./src/images/_DSC6046.JPG 1920w
          " sizes="50vw" alt="Lydia" />
            <h1 class="text-white italic relative z-10 px-4 md:px-8 py-5 font-swash antialiased text-5xl md:text-7xl">
                Lydia
            </h1>
        </div>
        <div class="p-4 md:p-8">
            <div class="[&_a]:hover:italic">
                <div class="space-y-4 md:space-y-6 pb-10 mb-10 border-b-10 border-red">
                    <p>
                        Lydia is a researcher, sound artist and computer musician who actively investigates the
                        alternative creativity of computational intelligence in sound. Through autonomous musical
                        systems that interact and improvise with human collaborators in multichannel contexts, she
                        explores how human and machine perceptions diverge, shaping distinct artistic interpretations
                        and
                        decisions. Her ongoing research is taking place in Sound & Music Computation at Music Technology
                        Group Barcelona where she
                        works on Systems & Multimedia architect with C++ / Vulkan / DSP / Concurrency.
                    </p>
                    <p>
                        Her current artistic interests are centered around computer music and noise, through algorithmic
                        composition, live coding, and sound installation, exploring musicality in noise within the
                        concepts of music, information, and systems.
                    </p>
                </div>
            </div>
            <!-- CONCERTS (table + all detailed works) -->
            <div class="pb-10 mb-10 border-b-10 border-red">
                <h2 class="mb-20 italic">Concerts</h2>
                <div class="[&_a]:hover:italic">
                    <table class="w-full">
                        <tbody>
                            <!-- 2025 -->
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">26/07/25</td>
                                <td class="pr-8 md:pr-16">
                                    Game of Life – "Zungentanz" (Wave Field Synthesis Festival)
                                </td>
                                <td class="pr-8 md:pr-16">The Hague, NL</td>
                                <td>
                                    192-channel WFS live coding (11′38, 2025)
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">25/05/25</td>
                                <td class="pr-8 md:pr-16">
                                    Trxxxter – Harmonica Concerto
                                </td>
                                <td class="pr-8 md:pr-16">Berlin, DE</td>
                                <td>DJ set / radio broadcast (42′15, 2025)</td>
                            </tr>
                            <!-- 2024 -->
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">08/09/24</td>
                                <td class="pr-8 md:pr-16">
                                    Wandering the Piano – Ars Electronica
                                </td>
                                <td class="pr-8 md:pr-16">Linz, AT</td>
                                <td>
                                    Sound installation (13′42, 2023) – presentation at Ars Electronica
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">08/03/24</td>
                                <td class="pr-8 md:pr-16">
                                    Wandering the Sounds of Languages
                                </td>
                                <td class="pr-8 md:pr-16">Den Haag, NL</td>
                                <td>
                                    <a href="https://youtu.be/YeBBEcqCik" target="_blank" rel="noopener noreferrer"
                                        class="text-lavender font-bold shadow-lg">
                                        concert / research presentation
                                    </a>
                                    (looped installation, 17′00, 2025)
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/02/24</td>
                                <td class="pr-8 md:pr-16">
                                    History Sampling Using Shaders
                                </td>
                                <td class="pr-8 md:pr-16">Online / various</td>
                                <td>
                                    GPU shader image sampler demo (Ongoing, 2024)
                                </td>
                            </tr>
                            <!-- 2023 -->
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">10/10/23</td>
                                <td class="pr-8 md:pr-16">
                                    Wandering the Piano – Venice Biennale Musica
                                </td>
                                <td class="pr-8 md:pr-16">Venice, IT</td>
                                <td>
                                    Sound installation (13′42, 2023)
                                    &nbsp;·&nbsp;
                                    <a href="https://www.labiennale.org/en/music/2023/music-performances/lydia-krifka-dobes-wandering-piano"
                                        target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                        Venice Biennale
                                    </a>
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/09/23</td>
                                <td class="pr-8 md:pr-16">
                                    Tracking Collection – Gesture-Tracking Library (preview)
                                </td>
                                <td class="pr-8 md:pr-16">The Hague, NL</td>
                                <td>
                                    Kinect / granular synthesis tools for Wave Field Synthesis performance (library,
                                    2023)
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/07/23</td>
                                <td class="pr-8 md:pr-16">Deutsche Oper – Common Sound (Micro-festival)</td>
                                <td class="pr-8 md:pr-16">Berlin, DE</td>
                                <td>
                                    Micro-festival curation / live intermedia performances (4-week residency, 2023)
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">24/03/23</td>
                                <td class="pr-8 md:pr-16">
                                    Radialsystem – Nomadism
                                </td>
                                <td class="pr-8 md:pr-16">Berlin, DE</td>
                                <td class="pr-8 md:pr-16">
                                    <a href="https://www.youtube.com/watch?v=MNdqoOIvFhc" target="_blank"
                                        rel="noopener noreferrer" class="text-lavender font-bold shadow-lg">live
                                        performance</a>
                                    (21′00, 2023)
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">18/04/23</td>
                                <td class="pr-8 md:pr-16">
                                    Realtime Processing Final Showcase using open source linux phone
                                </td>
                                <td class="pr-8 md:pr-16">The Hague, NL</td>
                                <td>24-channel multichannel installation (14′09, 2023)</td>
                            </tr>
                            <!-- 2022–2023 -->
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">04/11/22</td>
                                <td class="pr-8 md:pr-16">
                                    Twinthesizer 16-Ch Demo
                                </td>
                                <td class="pr-8 md:pr-16">Berlin, DE</td>
                                <td>
                                    <a href="https://www.youtube.com/wa?CrVUbrXE8" target="_blank"
                                        rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                        16-channel modular synth demo (9′54, 2022)
                                    </a>
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/09/22</td>
                                <td class="pr-8 md:pr-16">
                                    BLN Electroacoustics
                                </td>
                                <td class="pr-8 md:pr-16">Berlin, DE</td>
                                <td>
                                    Electroacoustic improvisation / extended-range violin + modular synth (16′22, 2022)
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/07/22</td>
                                <td class="pr-8 md:pr-16">
                                    Dynamic Stochastic Synthesis
                                </td>
                                <td class="pr-8 md:pr-16">Berlin, DE</td>
                                <td>
                                    Algorithmic composition code (Ongoing, 2022) – for Humboldt-Forum exhibition
                                </td>
                            </tr>
                            <!-- 2021 -->
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/06/21</td>
                                <td class="pr-8 md:pr-16">
                                    Stochastic Tendencies
                                </td>
                                <td class="pr-8 md:pr-16">The Hague, NL</td>
                                <td>
                                    Analogue studio generative composition (8′48, 2021)
                                </td>
                            </tr>
                            <!-- 2019–2020 -->
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/06/19</td>
                                <td class="pr-8 md:pr-16">
                                    Outflux – Live
                                </td>
                                <td class="pr-8 md:pr-16">Various venues (DE / IT)</td>
                                <td>
                                    Violin + electronics, smartphone apps, FFT cross synthesis (14′20, 2019)
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">15/08/19</td>
                                <td class="pr-8 md:pr-16">
                                    Common Sound at Deutsche Oper Berlin
                                </td>
                                <td class="pr-8 md:pr-16">Berlin, DE</td>
                                <td>
                                    Transcultural workshop lab / mini-festival curation (6-week residency, 2019)
                                </td>
                            </tr>
                            <!-- 2018 -->
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/03/18</td>
                                <td class="pr-8 md:pr-16">
                                    Categorical Perception of Microtonality
                                </td>
                                <td class="pr-8 md:pr-16">Germany (Jugend forscht)</td>
                                <td>
                                    Psychoacoustics research paper (First Prize, 2018)
                                </td>
                            </tr>
                            <!-- 2017 -->
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/11/17</td>
                                <td class="pr-8 md:pr-16">
                                    Working with Analogue Synth – "Impressions of Gagaku"
                                </td>
                                <td class="pr-8 md:pr-16">Germany (various festivals)</td>
                                <td>
                                    Electric violin + modular synth, three-movement composition (18′00, 2017)
                                </td>
                            </tr>
                            <!-- Code / tools as practice events (no strict venue) -->
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/10/24</td>
                                <td class="pr-8 md:pr-16">
                                    Patterns for C++
                                </td>
                                <td class="pr-8 md:pr-16">Online / various</td>
                                <td>
                                    Threaded pattern synthesis library (C++, ongoing since 2024)
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/06/24</td>
                                <td class="pr-8 md:pr-16">
                                    Contour &amp; Feature Tracker
                                </td>
                                <td class="pr-8 md:pr-16">Online / various</td>
                                <td>
                                    Real-time computer vision performance library (openFrameworks / C++, 2024+)
                                </td>
                            </tr>
                            <!-- Gyuchul / Guyshawn–style additions (5x, concerts/projects) -->
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">15/11/24</td>
                                <td class="pr-8 md:pr-16">
                                    Listening – Human–Machine Improvisation
                                </td>
                                <td class="pr-8 md:pr-16">The Hague</td>
                                <td>
                                    Multichannel AI–human improvisation system (4-channel live, 20′00, 2024)
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">29/11/24</td>
                                <td class="pr-8 md:pr-16">
                                    Errorist#1 – Relations
                                </td>
                                <td class="pr-8 md:pr-16">New Music Lab, The Hague, NL</td>
                                <td>
                                    Cellular-automata guided machine improvisation (multichannel performance, 18′00,
                                    2024)
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/10/23</td>
                                <td class="pr-8 md:pr-16">
                                    Unerhoerte Clouds_on Web
                                </td>
                                <td class="pr-8 md:pr-16">Online / Berlin, DE</td>
                                <td>
                                    AI + Web Audio browser installation (networked sound piece, 2023)
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">15/09/22</td>
                                <td class="pr-8 md:pr-16">
                                    Organotopia – "Untitled"
                                </td>
                                <td class="pr-8 md:pr-16">Berlin, DE</td>
                                <td>
                                    Kinetic laser + sound installation (site-specific media art, 2022)
                                </td>
                            </tr>
                            <tr class="align-top">
                                <td class="pr-8 md:pr-16">01/06/16</td>
                                <td class="pr-8 md:pr-16">
                                    Genes – "Mother Tongues"
                                </td>
                                <td class="pr-8 md:pr-16">Den Haag, NL</td>
                                <td>
                                    Generative visuals &amp; language-evolution installation (media art, 2016)
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <!-- All detailed project / piece descriptions (same text size) -->
                <div class="[&_a]:hover:italic space-y-10 mt-16">
                    <!-- WANDERING THE PIANO -->
                    <section>
                        <h4 class="font-bold mb-2">WANDERING THE PIANO</h4>
                        <p class="mb-3">
                            In 2023, I was selected as the youngest artist of the Venice Biennale Musica, chosen from
                            over 350 international applicants. Along with nine other composers, performers, and
                            musicians, I was awarded an artistic residency to produce my installation
                            <em>Wandering the Piano</em>, which premiered at the Biennale Musica di Venezia 2023 under
                            the curation of Lucia Ronchetti. The installation explores the spatial and mechanical memory
                            of the piano through fragmented motifs, prepared strings, and resonant responses to
                            movement, creating a dialogue between performer and instrument.
                            The work was supported by multiple research and creation grants and has been presented at
                            internationally renowned festivals, including La Biennale di Venezia (IT) and Ars
                            Electronica (AT). Through this installation, I investigated the relationship between gesture
                            and sonic memory, extending my research on interactive spatial sound and algorithmic
                            composition.
                        </p>
                        <p class="mb-3">
                            Small amateur film on YouTube:
                            <a href="https://www.youtube.com/watch?v=dts4YQDgXVw&amp;feature=youtu.be" target="_blank"
                                rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://www.youtube.com/watch?v=dts4YQDgXVw&amp;feature=youtu.be
                            </a>
                            <br />
                            Reference on the Biennale Website, with additional PDF:
                            <a href="https://www.labiennale.org/en/music/2023/music-performances/lydia-krifka-dobes-wandering-piano"
                                target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://www.labiennale.org/en/music/2023/music-performances/lydia-krifka-dobes-wandering-piano
                            </a>
                        </p>
                        <p>
                            <strong>Media:</strong> Sound installation / Multichannel spatial performance (24-channel)
                            <br />
                            <strong>Duration:</strong> 13′42<br />
                            <strong>Year:</strong> 2023
                        </p>
                        <p class="mt-3">
                        </p>
                    </section>
                    <!-- GAME OF LIFE -->
                    <section>
                        <h4 class="font-bold mb-2">GAME OF LIFE – "ZUNGENTANZ"</h4>
                        <p class="mb-3">
                            Wave field synthesis composition. <em>Zungentanz</em> (6'): the three main components of
                            this fixed media piece include spatial mapping of vowel positions to physical coordinates
                            using Wave Field Synthesis, extending micro-choreographies of speech articulation and the
                            mechanics of resonant acoustic memory within the oral cavity.
                        </p>
                        <p class="mb-3">
                            The idea of this project is to virtually place the listener inside the oral cavity of a
                            speaker to appreciate the complexity of movement while we speak. In particular, I observe
                            the vowels in the so-called vowel quadrant that identifies the position of the tongue (e.g.
                            i: high, front, u: high, back, a: low, central) and map them to virtual points in space
                            using Wave Field Analysis. I also want listeners to appreciate the diversity of human
                            languages, which have anything between two and around 25 vowels (e.g. Abkhaz vs. German, if
                            one counts the different realizations of lax and tense vowels).
                        </p>
                        <p class="mb-3">
                            Game of Life Festival:
                            <a href="https://www.koncon.nl/en/events/wave-field-synthesis-festival-2?d=45be0517"
                                target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://www.koncon.nl/en/events/wave-field-synthesis-festival-2?d=45be0517
                            </a>
                        </p>
                        <p>
                            <strong>Media:</strong> 192-channel (Wave Field Synthesis System) live coding<br />
                            <strong>Duration:</strong> 11′38<br />
                            <strong>Year:</strong> 2025
                        </p>
                    </section>
                    <!-- INSTITUTE OF SONOLOGY – GAME OF LIFE FESTIVAL -->
                    <section>
                        <h4 class="font-bold mb-2">INSTITUTE OF SONOLOGY – GAME OF LIFE FESTIVAL</h4>
                        <p class="mb-3">
                            The Hague, NL. Showcased at the Game of Life Festival as part of the Institute of Sonology's
                            featured presentations. The piece explored vowel space mapping through wave field synthesis,
                            creating a spatial sound environment where formants were diffused across hemispheric
                            loudspeaker arrays. Presented in the WFS auditorium using real-time multi-channel synthesis
                            tools.
                        </p>
                        <p>
                            <strong>Media:</strong> Wave Field Synthesis fixed media (192-channel system)<br />
                            <strong>Duration:</strong> 11′38<br />
                            <strong>Year:</strong> 26/07/2023
                        </p>
                    </section>
                    <!-- WANDERING THE SOUNDS OF LANGUAGES -->
                    <section>
                        <h4 class="font-bold mb-2">WANDERING THE SOUNDS OF LANGUAGES</h4>
                        <p class="mb-3">
                            There are two main components to this research:
                        </p>
                        <ul class="list-disc pl-8 mb-3">
                            <li>Curation and analysis of recordings of Aesop's fable in 22 highly diverse languages.
                            </li>
                            <li>Collective retelling of the story for an installation or a website on utterance level.
                            </li>
                        </ul>
                        <p class="mb-3">
                            Phonological fusion between languages based on k-means algorithms. Drawing from my
                            experience with different languages, from growing up trilingual to encountering the
                            languages of Vanuatu, I explore ways to appreciate the variety of spoken languages in their
                            acoustic realization. I work with recordings of the same text, a fable by Aesop, which
                            appeals to many cultures and carries great significance in the face of language
                            endangerment.
                        </p>
                        <p>
                            <strong>Media:</strong> Interactive sound/language installation + Website interface /
                            research concert<br />
                            <strong>Duration:</strong> 17′00 (looped installation)<br />
                            <strong>Year:</strong> 2025<br />
                            Den Haag, NL – concert-research presentation expanding on my thesis project, combining field
                            recordings of Aesop's Fable across 22 languages with live phonetic sonification. Audience
                            members interacted with an interface displaying parallel speech gestures as spatial sound
                            fields.
                        </p>
                    </section>
                    <!-- CONTOUR & FEATURE TRACKER -->
                    <section>
                        <h4 class="font-bold mb-2">CONTOUR &amp; FEATURE TRACKER</h4>
                        <p class="mb-3">
                            This is a reference implementation of my ongoing work with the openCV API. Once complete it
                            will be released both as a standalone library and openFrameworks add-on. I am using the
                            contour-finder algorithm (using kernel convolution techniques such as Sobel + Canny
                            edge-detection, etc.) to recognize contours from a moving image. Using the Shi-Tomasi
                            algorithm to define and extract features that can be selectively synthesized to form newer
                            shapes or animated to form distortions within the contours. All processing is done in
                            parallel using the POCO thread library.
                        </p>
                        <p class="mb-3">
                            The library has enhanced corner detection algorithms, expanded by me, that will directly
                            contribute to my research at Long Meadow Art Residency. It will help understand the
                            relationship between a movement artist and latent inanimate objects in the space.
                        </p>
                        <p>
                            <strong>Media:</strong> Real-time computer vision code for performance (openFrameworks /
                            C++)<br />
                            <strong>Duration:</strong> Ongoing<br />
                            <strong>Year:</strong> 2024+
                        </p>
                    </section>
                    <!-- HISTORY SAMPLING USING SHADERS -->
                    <section>
                        <h4 class="font-bold mb-2">HISTORY SAMPLING USING SHADERS</h4>
                        <p class="mb-3">
                            This library collects texture samples either from input video or a collection of images. In
                            this implementation, it uses the distance between mouse position and pixel in shaders to
                            sample different textures coordinated from the supplied deque of history to interpolate and
                            form new display images. In its next iteration, it will use gestures from LeapMotion instead
                            of mouse positions.
                        </p>
                        <p>
                            <strong>Media:</strong> GPU shader image sampler / Interactive visual system<br />
                            <strong>Duration:</strong> 6′00<br />
                            <strong>Year:</strong> 2024
                        </p>
                    </section>
                    <!-- DYNAMIC STOCHASTIC SYNTHESIS -->
                    <section>
                        <h4 class="font-bold mb-2">DYNAMIC STOCHASTIC SYNTHESIS</h4>
                        <p class="mb-3">
                            This library reimplements Xenakis and Sergio Luque's dynamic stochastic synthesis algorithm
                            in C++ using openFrameworks. Combined with my formants-detection tool, this system
                            recognizes vowels and extends them algorithmically, creating a method for exploring phonetic
                            diversity through computational means.
                        </p>
                        <p class="mb-3">
                            The project will be used in my upcoming exhibition at the Humboldt-Forum, demonstrating the
                            practical application of my research in linguistic sonification.
                        </p>
                        <p>
                            <strong>Media:</strong> Algorithmic composition code / C++ sound engine<br />
                            <strong>Duration:</strong> 10′00<br />
                            <strong>Year:</strong> 2022
                        </p>
                    </section>
                    <!-- TRACKING COLLECTION -->
                    <section>
                        <h4 class="font-bold mb-2">TRACKING COLLECTION</h4>
                        <p class="mb-3">
                            Below is a list of C++ projects (eventually turned into classes) I am writing as part of my
                            gesture-tracking library for my Bachelor's project at the Institute of Sonology. One of the
                            libraries shows how I create new parametric relationships from Kinect data (example: the
                            rotation of the knee with the speed of hand movement to form a single vector). Another
                            library shows using derivatives and statistical information from mouse movement to form new
                            animations on screen. It also has a first draft of a granular synthesis (credit Aaron
                            Anderson) to be used in my upcoming performance with a dancer at the WaveField Synthesis
                            festival.
                        </p>
                        <p class="mb-3">
                            This is the primary basis library for the gesture recognition phase of the work.
                        </p>
                        <p class="mb-3">
                            gesture derivatives:
                            <a href="https://drive.google.com/file/d/12MRekXJbVFOT4LYniq2w0cPhMErhMKm1/view?usp=drive_link"
                                target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/12MRekXJbVFOT4LYniq2w0cPhMErhMKm1/view?usp=drive_link
                            </a>
                            <br />
                            ni extensions:
                            <a href="https://drive.google.com/file/d/1d7JEMW_G3G59RBjSuMANiyLxd_EwPog5/view?usp=drive_link"
                                target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1d7JEMW_G3G59RBjSuMANiyLxd_EwPog5/view?usp=drive_link
                            </a>
                            <br />
                            granular kinect:
                            <a href="https://drive.google.com/file/d/1fibsZqPljY4paKomC_BO9XN3leC9nj32/view?usp=drive_link"
                                target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1fibsZqPljY4paKomC_BO9XN3leC9nj32/view?usp=drive_link
                            </a>
                        </p>
                        <p>
                            <strong>Media:</strong> Gesture-tracking research code (C++, Kinect / POCO Threads)<br />
                            <strong>Duration:</strong> N/A (library in progress)<br />
                            <strong>Year:</strong> 2023
                        </p>
                    </section>
                    <!-- UNKNOWN -->
                    <section>
                        <h4 class="font-bold mb-2">UNKNOWN</h4>
                        <p class="mb-3">
                            In 2022 &amp; 2023 I collaborated with contemporary dancer and choreographer Adithi Nodul.
                            The work focuses on exploring everyday gestures, both in their extent and in the emotions
                            they evoke. Music for the piece is parallel in places to the dance and accompanying in
                            others. The work is composed for extended range violin, freeze pedal, and convolution.
                            Constantly varying tempos, artificial harmonics overlapped by microtones, unsynced
                            counterpoint, and multiphonics are some of the concepts used for sound.
                        </p>
                        <p class="mb-3">
                            Dance explores gestures not just as artistic elements but to query the cultural space and
                            its
                            practices.
                        </p>
                        <p>
                            <strong>Media:</strong> Composition for choreography (Extended-range violin + dance)<br />
                            <strong>Duration:</strong> 12′15<br />
                            <strong>Year:</strong> 2022–2023
                        </p>
                    </section>
                    <!-- RADIALSYSTEM – NOMADISM -->
                    <section>
                        <h4 class="font-bold mb-2">RADIALSYSTEM – NOMADISM</h4>
                        <p class="mb-3">
                            Berlin, DE. A site-responsive live work presented at Radialsystem, combining violin
                            improvisation, sensor-based media, and streaming data visualizations of movement across
                            space. The performance dealt with the notion of "nomad listening" — sound as migration —
                            transforming real-time GPS traces into resonant audio textures.
                        </p>
                        <p>
                            <strong>Media:</strong> Live audiovisual performance with interactive mapping<br />
                            <strong>Duration:</strong> 21′00<br />
                            <strong>Year:</strong> 24/03/2023
                        </p>
                    </section>
                    <!-- REALTIME PROCESSING SHOWCASE -->
                    <section>
                        <h4 class="font-bold mb-2">REALTIME PROCESSING SHOWCASE</h4>
                        <p class="mb-3">
                            The Hague, NL. Experimental presentation exploring the relationship between motion, data,
                            and sound in multi-channel setups. The showcase featured algorithmically triggered visual
                            and sonic elements derived from dancer gesture capture using in-house gesture tracking
                            libraries.
                        </p>
                        <p>
                            <strong>Media:</strong> Multichannel installation (24-channel audio + real-time
                            processing)<br />
                            <strong>Duration:</strong> 14′09<br />
                            <strong>Year:</strong> 18/04/2023
                        </p>
                    </section>
                    <!-- DEUTSCHE OPER – COMMON SOUND (micro-festival) -->
                    <section>
                        <h4 class="font-bold mb-2">DEUTSCHE OPER – COMMON SOUND</h4>
                        <p class="mb-3">
                            Berlin, DE. Micro-festival curated and co-produced as part of <em>Common Sound</em> at the
                            Tischlerei, Deutsche Oper Berlin. The laboratory brought together young artists, composers,
                            and performers from diverse backgrounds to experiment across sound, gesture, and stage
                            media, culminating in a series of curated interdisciplinary performances with public
                            workshops.
                        </p>
                        <p>
                            <strong>Media:</strong> Micro-festival curation / live intermedia performance<br />
                            <strong>Duration:</strong> Residency 4 weeks<br />
                            <strong>Year:</strong> 01/07/2023
                        </p>
                    </section>
                    <!-- TWINTHESIZER 16-CH DEMO -->
                    <section>
                        <h4 class="font-bold mb-2">TWINTHESIZER 16-CH DEMO</h4>
                        <p class="mb-3">
                            Berlin, DE. Prototype presentation and tech demo for <em>Twinthesizer</em>, a dual-engine
                            16-channel modular synthesizer system enabling simultaneous analog and granular synthesis.
                            The event was a short live improvisation, focusing on cross-modulation between two
                            FPGA-driven oscillator banks and spatially diffused harmonics.
                        </p>
                        <p>
                            <strong>Media:</strong> 16-channel modular synth demonstration (live)<br />
                            <strong>Duration:</strong> 9′54<br />
                            <strong>Year:</strong> 04/11/2022
                        </p>
                    </section>
                    <!-- TRXXXTER – HARMONICA CONCERTO -->
                    <section>
                        <h4 class="font-bold mb-2">TRXXXTER – HARMONICA CONCERTO</h4>
                        <p class="mb-3">
                            Berlin, DE. DJ-set installation and live radio project fusing generative sampling with
                            manipulated harmonica recordings. The performance transformed field textures into cyclical
                            layers through granular processing, creating a hybrid between DJ practice, sound collage,
                            and live coding. Broadcast as part of the <em>Trxxxter Radio Performance Series.</em>
                        </p>
                        <p>
                            <strong>Media:</strong> DJ set / radio broadcast with live sampling<br />
                            <strong>Duration:</strong> 42′15<br />
                            <strong>Year:</strong> 25/05/2025
                        </p>
                    </section>
                    <!-- BLN ELECTROACOUSTICS -->
                    <section>
                        <h4 class="font-bold mb-2">BLN ELECTROACOUSTICS</h4>
                        <p class="mb-3">
                            An improvisers collective was formed by me in Berlin to create a mix of traditional
                            instruments, everyday objects with contact mics, one analog synthesizer (Eurorack), some
                            programming languages, and manipulated playback of field recordings. The recordings consist
                            of acoustic violin, PureData, vibrating plates, bowed clothes string, a Eurorack synth, and
                            clarinet.
                        </p>
                        <p class="mb-3">
                            Medium: exploration for extended range violin + modular synth + manipulated field recording
                            of a train station. This recording consists of manipulation of field recordings and samples
                            from the field recording as an impulse response for violin convolution.
                        </p>
                        <p>
                            <strong>Media:</strong> Electroacoustic improvisation / Hybrid analog-digital ensemble<br />
                            <strong>Duration:</strong> 16′22<br />
                            <strong>Year:</strong> 2022
                        </p>
                    </section>
                    <!-- PATTERNS FOR C++ -->
                    <section>
                        <h4 class="font-bold mb-2">PATTERNS FOR C++</h4>
                        <p class="mb-3">
                            I have been writing multi-threaded classes for C++ to mimic Patterns UGens from
                            SuperCollider. This link tracks the progress of the project. As of now, calling (threaded)
                            libraries with either user-defined functions/lambdas for patterns or using any of the member
                            pattern functions have been implemented.
                        </p>
                        <p class="mb-3">
                            threaded patterns main link:
                            <a href="https://drive.google.com/file/d/1E2ptHYe2DnNCncTwB-Xw2yHH-KCmNpXz/view?usp=drive_link"
                                target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1E2ptHYe2DnNCncTwB-Xw2yHH-KCmNpXz/view?usp=drive_link
                            </a>
                        </p>
                        <p>
                            <strong>Media:</strong> Threaded pattern synthesis library (C++)<br />
                            <strong>Duration:</strong> Continuous development<br />
                            <strong>Year:</strong> 2024
                        </p>
                    </section>
                    <!-- STOCHASTIC TENDENCIES -->
                    <section>
                        <h4 class="font-bold mb-2">STOCHASTIC TENDENCIES</h4>
                        <p class="mb-3">
                            The principal concept behind this composition is tendency masks. A tendency mask is a method
                            of containing, enveloping, or masking stochastic processes or events into organized
                            tendencies. Each of these parameters has an element of chance. Pitch/frequency is generated
                            by binary scaling white noise in eight division bands, the sum of which modulates the
                            frequency of a function generator. The random texture is created by multiplying the function
                            generator output with a controlled random pulse generator.
                        </p>
                        <p class="mb-3">
                            The phrasing is generated by four random envelope generators, summed using a mixing
                            amplifier, the levels on the mixing amplifier determining a variety of phrases.
                        </p>
                        <p class="mb-3">
                            <a href="https://drive.google.com/file/d/1CgmbqdDxICZjfjskqgHLoF4SJi_pC4P6/view?usp=drive_link"
                                target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                Listen: Stochastic Tendencies
                            </a>
                        </p>
                        <p>
                            <strong>Media:</strong> Analogue studio generative composition (Institute of Sonology)<br />
                            Developed in the analogue studio that continues the tradition of the former Philips
                            electronic music studio in Eindhoven.<br />
                            <strong>Duration:</strong> 8′48<br />
                            <strong>Year:</strong> 2021
                        </p>
                    </section>
                    <!-- OUTFLUX -->
                    <section>
                        <h4 class="font-bold mb-2">OUTFLUX</h4>
                        <p class="mb-3">
                            A live improvisation trio consisting of me on the violin and electronics, Tristan Beutr on
                            smartphone apps, and Riccardo Davide on FFT cross synthesis via Max and Wacom tablet. The
                            central concept behind the trio is the conceptual and literal exchange of ideas. Sound
                            output from each member is sent to every other member in order to be processed or tweaked
                            live.
                        </p>
                        <p class="mb-3">
                            <a href="https://soundcloud.com/grunfeld/adblock-module/s-d45w5" target="_blank"
                                rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                Listen: Adblock Module
                            </a>
                        </p>
                        <p>
                            <strong>Media:</strong> Live trio (FFT cross synthesis + violin + phone apps)<br />
                            <strong>Duration:</strong> 14′20<br />
                            <strong>Year:</strong> 2019
                        </p>
                    </section>
                    <!-- CATEGORICAL PERCEPTION OF MICROTONALITY -->
                    <section>
                        <h4 class="font-bold mb-2">CATEGORICAL PERCEPTION OF MICROTONALITY</h4>
                        <p class="mb-3">
                            There are four main components to this research study:
                        </p>
                        <ul class="list-disc pl-8 mb-3">
                            <li>Survey of historical approaches to microtonality from multiple traditions.</li>
                            <li>Experimental investigation of tone perception across diverse backgrounds.</li>
                            <li>Creation of an empirical study of categorical boundaries in microtonal discrimination.
                            </li>
                            <li>Examination of microtonal intervals in contemporary applications.</li>
                        </ul>
                        <p class="mb-3">
                            <a href="https://drive.google.com/file/d/1oCCvuNM_dlYrX42v_MkD9c2fg3nHulHV/view?usp=sharing"
                                target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                Research paper
                            </a>
                        </p>
                        <p>
                            <strong>Media:</strong> Research paper / Psychoacoustics study<br />
                            <strong>Duration:</strong> N/A<br />
                            <strong>Year:</strong> 2018
                        </p>
                    </section>
                    <!-- WORKING WITH ANALOGUE SYNTH -->
                    <section>
                        <h4 class="font-bold mb-2">WORKING WITH ANALOGUE SYNTH – "IMPRESSIONS OF GAGAKU"</h4>
                        <p class="mb-3">
                            My first introduction to synthesizers was through DALIN, who assembled a comprehensive
                            Eurorack synthesizer setup in Berlin and Den Haag. We started collaboration in 2017 with
                            improvised performance sessions in various festivals, culminating with a composition
                            called <em>Gagaku</em>.
                        </p>
                        <p class="mb-3">
                            This piece concentrates on aspects of Gagaku such as its timbral and spectral richness, its
                            openness in rhythm, its minimalism, and chiefly the different tuning systems.
                        </p>
                        <p class="mb-3">
                            <a href="https://soundcloud.com/grunfeld/impressions-of-gagaku-1" target="_blank"
                                rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                Listen: Impressions of Gagaku
                            </a>
                        </p>
                        <p>
                            <strong>Media:</strong> Analog modular synthesis + violin improvisation<br />
                            <strong>Duration:</strong> 18′00<br />
                            <strong>Year:</strong> 2017
                        </p>
                    </section>
                    <!-- DEUTSCHE OPER – COMMON SOUND (HYBRID OPERA LAB) -->
                    <section>
                        <h4 class="font-bold mb-2">DEUTSCHE OPER – COMMON SOUND (HYBRID OPERA LAB)</h4>
                        <p class="mb-3">
                            <strong>DEUTSCHE OPER – COMMON SOUND</strong><br />
                            Berlin, DE.<br />
                            Curated lab at Tischlerei, Deutsche Oper Berlin, for young artists 15+ prototyping hybrid
                            opera: oud-violin, santoor choirs, Persian rap + electro beats. Students co-created live
                            musical theatre exploring embodied media and gesture-driven performance.
                        </p>
                        <p class="mb-3">
                            <a href="https://www.youtube.com/watch?v=lfs_h92yqp0" target="_blank"
                                rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                Watch: Common Sound 2023
                            </a>
                        </p>
                        <p>
                            <strong>Media:</strong> Hybrid opera lab / Transdisciplinary curation<br />
                            <strong>Duration:</strong> 4-week residency<br />
                            <strong>Year:</strong> 2019
                        </p>
                    </section>
                    <!-- COMMON SOUND at DEUTSCHE OPER BERLIN (internship / mentorship) -->
                    <section>
                        <h4 class="font-bold mb-2">COMMON SOUND at DEUTSCHE OPER BERLIN</h4>
                        <p class="mb-3">
                        </p>
                        <p class="mb-3">
                        </p>
                        <p class="mb-3">
                            To answer these questions, I helped curate an event at the Tischlerei at the Deutsche Oper
                            Berlin as an imaginative future laboratory of sounds. Artists from different disciplines
                            were invited: visual artists, dancers, DJs, VJs, composers, and authors were selected to
                            lead workshops and write several new pieces of musical theatre to be performed at the
                            Tischlerei over a three-part evening. The pieces were performed, sung, and produced by young
                            students from Berlin aged 15 and up. COMMON SOUND was funded by the Federal Ministry of
                            Education and Research.
                        </p>
                        <p>
                            <strong>Media:</strong> Interdisciplinary workshop / Festival curation<br />
                            <strong>Duration:</strong> Project residency, 6 weeks<br />
                            <strong>Year:</strong> 2019
                        </p>
                    </section>
                    <!-- ELECTROACOUSTIC ENSEMBLE -->
                    <section>
                        <h4 class="font-bold mb-2">ELECTROACOUSTIC ENSEMBLE</h4>
                        <p class="mb-3">
                            Electroacoustic Ensemble comprises students, faculty, and alumni of the Institute of
                            Sonology. It helped me view musical space in a new light. My experience in improvisation had
                            predominantly been through interaction and gesture; through the ensemble I learned to focus
                            on forming a larger whole, more akin to layers that form a painting or the life defined by a
                            particle system animation.
                        </p>
                        <p>
                            <strong>Media:</strong> Large electroacoustic ensemble performance<br />
                            <strong>Duration:</strong> N/A<br />
                            <strong>Year:</strong> 2022
                        </p>
                    </section>
                    <!-- UNERHÖRT -->
                    <section>
                        <h4 class="font-bold mb-2">UNERHÖRT</h4>
                        <p class="mb-3">
                            Machines reflect the desire for control, embodying our expectations of the 'other,' which
                            often results in imbalanced power dynamics centered around ourselves. While we are confined
                            to our own perspectives, could there still be ways to genuinely listen to others? Is there
                            something worth exploring in the potential intersections?
                        </p>
                        <p class="mb-3">
                            UNERHÖRT is a multidisciplinary research project encompassing sound art, computer software
                            development and improvisational movement. In recent years, the use of artificial
                            intelligence (AI) in creative productions has become increasingly common, raising
                            existential questions about humanity – particularly regarding the possibility of computers
                            outperforming humans. The fear stems from the prioritisation of 'human-like AI' development,
                            which tends to overlook the fundamental differences between humans and machines. In the
                            context of generative AI, its creative output is often evaluated solely through the lens of
                            our aesthetics.
                        </p>
                        <p class="mb-3">
                            UNERHÖRT emphasizes the dynamics of collaboration rather than control in human-machine
                            relationships. Through collaboration with Butoh dancers and contemporary choreographers
                            (Anita Nodul), it seeks to present an improvisational dialogue between human and machine,
                            exploring the intersection of sound, computation, and dance.
                        </p>
                        <p>
                            <strong>Media:</strong> 4-channel live | Collaborator (Dance): Anita Nodul<br />
                            <strong>Duration:</strong> 20′<br />
                            <strong>Year:</strong> 2025
                        </p>
                    </section>
                    <!-- FAKE NOISE! -->
                    <section>
                        <h4 class="font-bold mb-2">FAKE NOISE!</h4>
                        <p class="mb-3">
                            The series of events aims to build a platform for exploration of the realities surrounding
                            objects. Objects are full of hidden meanings and interactions that extend beyond their
                            appearance, indicating that they are constituted not only socially but also through physical
                            and technological processes. Technologically-mediated environments for audio generation
                            allow one to reveal speculative realities of sound objects. The eperformance was supposed to
                            emphasise the tension between perceived sound (fetish) and its underlying structure (fact),
                            inviting participants to engage with the duality of sound as both an object of perception
                            and an independent entity. 'FAKE NOISE!' presuppose the existence of objects that
                            intermediate the way they are perceived (fetish) and their reality (fact).
                        </p>
                        <p>
                            <strong>Media:</strong> Duo Improvisation / Live coding<br />
                            <strong>Year:</strong> Ongoing
                        </p>
                    </section>
                    <!-- MOTHER TONGUES -->
                    <section>
                        <h4 class="font-bold mb-2">MOTHER TONGUES</h4>
                        <p class="mb-3">
                            "By 2100, more than half of the 7,000-plus languages spoken on Earth—many of them not yet
                            recorded—may disappear. When the last speaker of a language dies, the world loses a wealth
                            of information about history, culture, the natural environment, and the human brain." —
                            David Harrison
                        </p>
                        <p class="mb-3">
                            Each word in the string is selected from within the genetic pool and is generated based on
                            the underlying genetic elements (persistence, variation, transformation). The previously
                            generated words are influenced by genetic factors and affect the generation of the next
                            word. The ultimate result of evolution is the word 'Mother Tongues', which visualizes the
                            process of variation. The visuals of the genealogy symbolize the irreplaceable traits and
                            prototypes of cultures with different languages.
                        </p>
                        <p>
                            <strong>Media:</strong> Generative Visuals | Media Art Project<br />
                            <strong>Year:</strong> 2016
                        </p>
                    </section>
                    <!-- SOUND & SPACE WORKSHOP -->
                    <section>
                        <h4 class="font-bold mb-2">SOUND & SPACE WORKSHOP</h4>
                        <p class="mb-3">
                            Comprehensive workshop series exploring the materiality and spatiality of sound through
                            multiple sessions: acousmatrix (field recordings and Islamic adhan compositions), sound &
                            space (12-channel dodecaphonic systems), philosophical investigations of sound's nature,
                            n-channel reverb implementations, microphone techniques (coincident and spaced pairs),
                            hybrid spatial approaches combining Chladni figures and Harry Partch's tuning systems, and
                            Japanese concepts of onkyō (sound + resonance).
                        </p>
                        <p>
                            <strong>Media:</strong> Workshop series<br />
                            <strong>Location:</strong> Barcelona<br />
                            <strong>Year:</strong> Forthcoming
                        </p>
                    </section>
                </div>
            </div>
            <!-- END CONCERTS -->
        </div>
        <div class="grid md:grid-cols-2 lg:grid-cols-4 gap-12 pb-20 mb-20 border-b-10 border-lavender">
            <div class="aspect-square w-full">
                <a href="https://drive.google.com/file/d/1CgmbqdDxICZjfjskqgHLoF4SJi_pC4P6/view?usp=drive_link"
                    target="_blank" rel="noopener noreferrer"
                    class="block w-full h-full bg-gray-200 hover:bg-gray-300 flex items-center justify-center text-center p-4">
                    <span class="font-bold">Stochastic Tendencies</span>
                </a>
            </div>
            <div class="aspect-square w-full">
                <a href="https://soundcloud.com/grunfeld/adblock-module/s-d45w5" target="_blank"
                    rel="noopener noreferrer"
                    class="block w-full h-full bg-gray-200 hover:bg-gray-300 flex items-center justify-center text-center p-4">
                    <span class="font-bold">Adblock Module (Outflux)</span>
                </a>
            </div>
            <div class="aspect-square w-full">
                <a href="https://soundcloud.com/grunfeld/impressions-of-gagaku-1" target="_blank"
                    rel="noopener noreferrer"
                    class="block w-full h-full bg-gray-200 hover:bg-gray-300 flex items-center justify-center text-center p-4">
                    <span class="font-bold">Impressions of Gagaku</span>
                </a>
            </div>
            <div class="aspect-square w-full">
                <a href="https://www.youtube.com/watch?v=lfs_h92yqp0" target="_blank" rel="noopener noreferrer"
                    class="block w-full h-full bg-gray-200 hover:bg-gray-300 flex items-center justify-center text-center p-4">
                    <span class="font-bold">Common Sound 2023 (Video)</span>
                </a>
            </div>
        </div>
        <!-- Coursework Section (keep this one) -->
        <div class="pb-10 mb-10 border-b-10 border-red px-4 md:px-8">
            <h3 class="mb-20 italic">Classes Sound and Music Computation</h3>
            <div class="[&_a]:hover:italic space-y-6">
                <p>
                    <strong>DSP for sound and music</strong><br />
                    Methods for analysing and transforming audio using spectral and time-domain techniques,
                    directly relevant to spatial sound, ambisonics, and sound design workflows.
                    <a href="https://www.upf.edu/en/web/smc/academic-program" target="_blank" rel="noopener noreferrer"
                        class="text-blue font-bold shadow-lg">
                        upf program
                    </a>
                </p>
                <p>
                    <strong>ML for sound and music</strong><br />
                    Deep learning methods for audio and music representations, useful for feature extraction,
                    corpus-based composition, and experimental models on multilingual speech and phonetics.
                </p>
                <p>
                    <strong>Generative algorithms for sound and music</strong><br />
                    generative ai approaches in symbolic and audio domains, aligned with my practice in
                    algorithmic composition, stochastic systems, and interactive sound installations.
                </p>
                <p>
                    <strong>Music Information Retrieval</strong><br />
                    techniques for describing audio content (timbre, rhythm, harmony, mood, etc.) and building
                    searchable sound corpora, close to my work with large language and audio datasets.
                </p>
                <p>
                    <strong>advanced computing techniques for sound and music</strong><br />
                    state-of-the-art methods for automatic processing of music content, bridging my low-level
                    c++ / dsp interests with higher-level creative tools.
                </p>
                <p>
                    <strong>advanced interface design</strong><br />
                    paradigms and tools for multimodal interfaces between humans and computational systems,
                    relevant for sensor-based installations, live-coding performance, and experimental instrument
                    design.
                </p>
                <p>
                    <strong>music perception and cognition</strong><br />
                    empirical and computational perspectives on how humans perceive sound, rhythm, tonality,
                    and emotion in music — directly connected to my interest in linguistic prosody and listening
                    behaviour.
                </p>
            </div>
        </div>
        <!-- Coursework Institute of Sonology (keep this one) -->
        <div class="pb-20 mb-20 border-b-10 border-red px-4 md:px-8">
            <h3 class="mb-20 italic">Coursework at Institute of Sonology</h3>
            <div class="[&_a]:hover:italic">
                <p>
                    <a href="https://youtu.be/AMHudg45Svs" class="text-blue font-bold shadow-lg" target="_blank">3D ML
                        for audio</a>,
                    Audiovisual Installation – Live Coding, Venice, October 2023
                </p>
                <p>
                    <a href="https://www.instagram.com/kindheitsbotschaft" class="text-lavender font-bold shadow-lg"
                        target="_blank">DSP</a>,
                    Collaborative Live Experiment – Live Coding & Instrument,
                    Harmonica Concerto @ Trxxxter, Berlin, March 2025
                </p>
                <p>
                    <a href="https://youtu.be/4rS13bgADwA" class="text-olive font-bold shadow-lg" target="_blank">Sound
                        Space and Time</a>,
                    Audiovisual Performance – Live Coding & Instrument Processing, The Hague, October 2024
                </p>
                <p>
                    <a href="https://youtu.be/4rS13bgADwA" class="text-olive font-bold shadow-lg"
                        target="_blank">Supercollider</a>,
                    Audiovisual Performance – Live Coding & Instrument Processing, The Hague, October 2024
                </p>
                <p>
                    <a href="https://www.javkhlan-ariunbold.com/ovoo.html" class="text-blue font-bold shadow-lg"
                        target="_blank">Realtime processes</a>,
                    Video Installation – Sounddesign, Cologne, June 2024
                </p>
                <p>
                    <a href="https://www.youtube.com/watch?v=YeBBEcqCikg" class="color-red font-bold shadow-lg"
                        target="_blank">Physical Modeling</a>,
                    Audiovisual Installation – Sounddesign, Amsterdam, March 2024
                </p>
            </div>
        </div>
        <!-- Residencies Section -->
        <div class="pb-20 mb-20 border-b-10 border-blue px-4 md:px-8">
            <h3 class="mb-20 italic">Residencies</h3>
            <div class="[&_a]:hover:italic">
                <ul class="space-y-4">
                    <li>
                        Residency at Venice Biennale Musica with
                        Miller Smith Puckette: Composing for the Grand Piano<br />
                        INA GRM, Venice, IT (October 2025 – June 2026)
                    </li>
                    <li>
                        Residency at SFPC<br />
                        School for Poetic Computation, NYC (August 2025)
                    </li>
                    <li>
                        Residency at Darmstadt Summer course with Steven Takasugi, Chaya Czernowyn and Sara
                        Nemtsov<br />
                        Darmstadt Summer School, Darmstadt (August 2025)
                    </li>
                    <li>
                        Residency at Composition Tage<br />
                        Winner of Composition award, Berlin 2025
                    </li>
                </ul>
            </div>
        </div>
        <!-- References Section -->
        <div class="pb-20 mb-20 border-b-10 border-blue px-4 md:px-8">
            <h3 class="mb-20 italic">References</h3>
            <div class="[&_a]:hover:italic">
                <div class="mb-20">
                    <p><strong>Gerfried Stocker</strong><br>
                        Ars Electronica, Artistic Director<br>
                        <a href="https://arselectronica.au" target="_blank" rel="noopener noreferrer"
                            class="text-lavender font-bold shadow-lg">
                            Ars Electronica
                        </a>
                    </p>
                </div>
                <div class="mb-20">
                    <p><strong>Miller Smith Puckette</strong><br>
                        <a href="https://www.mpuckette.ucsd" target="_blank" rel="noopener noreferrer"
                            class="text-lavender font-bold shadow-lg">
                            Miller Puckette
                        </a>
                    </p>
                </div>
                <div class="mb-20">
                    <strong>Richard Barrett</strong><br>
                    Institute of Sonology, Composer, Lecturer, Performer<br>
                    <a href="https://www.nts.live/shupsammy/episodes/upsammy-5th-september-2024" target="_blank"
                        rel="noopener noreferrer" class="text-lavender font-bold shadow-lg">
                        Richard Barrett
                    </a>
                    </p>
                </div>
            </div>
            <div class="border-b-10 border-lavender mb-10"></div>
            <div
                class="font-serif [&_a]:hover:not-italic md:grid md:grid-cols-2 md:gap-12 bg-pink p-10 rounded-2xl text-black antialiased mb-10">
                <div class="flex flex-col justify-between mb-6 md:mb-0">
                    <h3 id="swimmingpool" class="mb-6">errorist</h3>
                    <div class="italic">
                        <p><a href="mailto:lydiakrifka@gmail.com">Bookings</a></p>
                        <p><a href="https://soundcloud.com/grunfeld">Soundcloud</a></p>
                        <p><a href="https://www.instagram.com/lydia.krifkadobes">Instagram</a></p>
                    </div>
                    <div
                        class="grid grid-cols-2 gap-12 [&_a]:hover:not-italic mt-10 pt-10 border-t-10 border-lavender mb-10">
                        <p class="font-swash italic">Lydia</p>
                        <div class="italic">
                            <p><a href="mailto:lydiakrifka@gmail.com">Mail</a></p>
                            <p>
                                <a href="https://soundcloud.com/errorist">Soundcloud</a>
                            </p>
                            <p>
                                <a href="https://pastagang.bandcamp.com/">Bandcamp</a>
                            </p>
                            <p><a href="https://www.instagram.com/lydia.krifkadobes/">Instagram</a></p>
                        </div>
                    </div>
                </div>
            </div>
    </main>
</body>

</html>
